{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "024803fa-ead2-4078-a930-53aaf0843de0",
   "metadata": {},
   "source": [
    "## Data acquisition to create wp_politicians_by_country.csv file\n",
    "\n",
    "### Assumptions\n",
    "* The environment variables `USER_NAME` and `ACCESS_TOKEN` have been set before running this notebook via the command `source creds.sh`.\n",
    "Make sure to go into the `creds.sh` file and replace the variables with appropriate values.\n",
    "\n",
    "* All data files (.csv etc) live at the same level as this notebook.\n",
    "\n",
    "### Description\n",
    "\n",
    "The notebook is intended to be ran in sequential order.\n",
    "\n",
    "The goal of this notebook is to use data from `politicians_by_country_AUG.2024.csv` and `population_by_country_AUG.2024.csv` to call various Wikipedia API functions.\n",
    "\n",
    "First, the `revision_id` (known as `lastrevid` to the Wikipedia data scheme) is obtained by calling the Wikipedia API using the `request_pageinfo_per_article()` function in the notebook below.\n",
    "This function will take the title of a Wikipedia article, in this case the name of a politician, and return a plethora of information about the article. The `lastrevid` will be extracted\n",
    "from the API response and saved as `revision_id`.\n",
    "\n",
    "Second, the `revision_id` will be provided to the ORES Wikipedia classification algorithm via an API call which will provide a classification prediction of article quality for the Wikipedia article associated with a politician.\n",
    "\n",
    "Third, data from the `population_by_country_AUG.2024.csv` file will be munged to aggregate countries with their particular region so that a politician can be grouped with an appropriate region.\n",
    "\n",
    "Finally, all the above information will be grouped together in a final dictionary with the following schema: `country`, `region`, `population`, `article_title`, `revision_id`, `article_quality`.\n",
    "This final dictionary will be transformed into a Pandas DataFrame and saved to .csv format.\n",
    "\n",
    "During each step above, if a politician does not return a `lastrevid` or an ORES score, they will be logged and saved to a seperate file noting they lacked appropriate information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6c433fd-7102-411b-ba34-e4b6611ccd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os, pickle, time, urllib.parse\n",
    "import requests\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "005a608c-595a-45c0-a82c-ddc35c1f6d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load csv data into Pandas Dataframes\n",
    "\"\"\"\n",
    "politicians_df = pd.read_csv('politicians_by_country_AUG.2024.csv')\n",
    "population_df = pd.read_csv('population_by_country_AUG.2024.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c3a74ef-eb7a-4225-af18-002ead557a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Constants setup ahead of time for Wikipedia API calls using the `request_pageinfo_per_article()` function below.\n",
    "\"\"\"\n",
    "\n",
    "# The basic English Wikipedia API endpoint\n",
    "API_ENWIKIPEDIA_ENDPOINT = \"https://en.wikipedia.org/w/api.php\"\n",
    "API_HEADER_AGENT = 'User-Agent'\n",
    "\n",
    "# We'll assume that there needs to be some throttling for these requests - we should always be nice to a free data resource\n",
    "API_LATENCY_ASSUMED = 0.002       # Assuming roughly 2ms latency on the API and network\n",
    "API_THROTTLE_WAIT = (1.0/100.0)-API_LATENCY_ASSUMED\n",
    "\n",
    "# When making automated requests we should include something that is unique to the person making the request\n",
    "# This should include an email - your UW email would be good to put in there\n",
    "REQUEST_HEADERS = {\n",
    "    'User-Agent': 'dtropf@uw.edu, University of Washington, MSDS DATA 512 - AUTUMN 2024'\n",
    "}\n",
    "\n",
    "# This is a string of additional page properties that can be returned see the Info documentation for\n",
    "# what can be included. If you don't want any this can simply be the empty string\n",
    "PAGEINFO_EXTENDED_PROPERTIES = \"talkid|url|watched|watchers\"\n",
    "#PAGEINFO_EXTENDED_PROPERTIES = \"\"\n",
    "\n",
    "# This template lists the basic parameters for making this\n",
    "PAGEINFO_PARAMS_TEMPLATE = {\n",
    "    \"action\": \"query\",\n",
    "    \"format\": \"json\",\n",
    "    \"titles\": \"\",           # to simplify this should be a single page title at a time\n",
    "    \"prop\": \"info\",\n",
    "    \"inprop\": PAGEINFO_EXTENDED_PROPERTIES\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57efeac0-0815-484f-8433-2234278b7f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create function to obtain relevant information from a Wikipedia page based on the Wikipedia article title.\n",
    "Will return `lastrevid` which will be used for `revision_id` later in the notebook.\n",
    "\"\"\"\n",
    "\n",
    "def request_pageinfo_per_article(article_title = None, \n",
    "                                 endpoint_url = API_ENWIKIPEDIA_ENDPOINT, \n",
    "                                 request_template = PAGEINFO_PARAMS_TEMPLATE,\n",
    "                                 headers = REQUEST_HEADERS):\n",
    "    \"\"\"\n",
    "    Calls Wikipedia API to obtain page information for `article_title`.\n",
    "    Returns JSON of information according to arguments in `request_template` and `headers`.\n",
    "    \"\"\"\n",
    "    \n",
    "    # article title can be as a parameter to the call or in the request_template\n",
    "    if article_title:\n",
    "        request_template['titles'] = article_title\n",
    "\n",
    "    if not request_template['titles']:\n",
    "        raise Exception(\"Must supply an article title to make a pageinfo request.\")\n",
    "\n",
    "    if API_HEADER_AGENT not in headers:\n",
    "        raise Exception(f\"The header data should include a '{API_HEADER_AGENT}' field that contains your UW email address.\")\n",
    "\n",
    "    if 'uwnetid@uw' in headers[API_HEADER_AGENT]:\n",
    "        raise Exception(f\"Use your UW email address in the '{API_HEADER_AGENT}' field.\")\n",
    "\n",
    "    # make the request\n",
    "    try:\n",
    "        # we'll wait first, to make sure we don't exceed the limit in the situation where an exception\n",
    "        # occurs during the request processing - throttling is always a good practice with a free\n",
    "        # data source like Wikipedia - or any other community sources\n",
    "        if API_THROTTLE_WAIT > 0.0:\n",
    "            time.sleep(API_THROTTLE_WAIT)\n",
    "        response = requests.get(endpoint_url, headers=headers, params=request_template)\n",
    "        json_response = response.json()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        json_response = None\n",
    "    return json_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e538c263-296f-4504-b9a8-78ba0a73ee39",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batchcomplete': '', 'query': {'pages': {'-1': {'ns': 0, 'title': 'Barbara Eibinger-Miedl', 'missing': '', 'contentmodel': 'wikitext', 'pagelanguage': 'en', 'pagelanguagehtmlcode': 'en', 'pagelanguagedir': 'ltr', 'fullurl': 'https://en.wikipedia.org/wiki/Barbara_Eibinger-Miedl', 'editurl': 'https://en.wikipedia.org/w/index.php?title=Barbara_Eibinger-Miedl&action=edit', 'canonicalurl': 'https://en.wikipedia.org/wiki/Barbara_Eibinger-Miedl'}}}}\n",
      "{'batchcomplete': '', 'query': {'pages': {'-1': {'ns': 0, 'title': 'Mehrali Gasimov', 'missing': '', 'contentmodel': 'wikitext', 'pagelanguage': 'en', 'pagelanguagehtmlcode': 'en', 'pagelanguagedir': 'ltr', 'fullurl': 'https://en.wikipedia.org/wiki/Mehrali_Gasimov', 'editurl': 'https://en.wikipedia.org/w/index.php?title=Mehrali_Gasimov&action=edit', 'canonicalurl': 'https://en.wikipedia.org/wiki/Mehrali_Gasimov'}}}}\n",
      "{'batchcomplete': '', 'query': {'pages': {'-1': {'ns': 0, 'title': 'Kyaw Myint', 'missing': '', 'contentmodel': 'wikitext', 'pagelanguage': 'en', 'pagelanguagehtmlcode': 'en', 'pagelanguagedir': 'ltr', 'fullurl': 'https://en.wikipedia.org/wiki/Kyaw_Myint', 'editurl': 'https://en.wikipedia.org/w/index.php?title=Kyaw_Myint&action=edit', 'canonicalurl': 'https://en.wikipedia.org/wiki/Kyaw_Myint'}}}}\n",
      "{'batchcomplete': '', 'query': {'pages': {'-1': {'ns': 0, 'title': 'André Ngongang Ouandji', 'missing': '', 'contentmodel': 'wikitext', 'pagelanguage': 'en', 'pagelanguagehtmlcode': 'en', 'pagelanguagedir': 'ltr', 'fullurl': 'https://en.wikipedia.org/wiki/Andr%C3%A9_Ngongang_Ouandji', 'editurl': 'https://en.wikipedia.org/w/index.php?title=Andr%C3%A9_Ngongang_Ouandji&action=edit', 'canonicalurl': 'https://en.wikipedia.org/wiki/Andr%C3%A9_Ngongang_Ouandji'}}}}\n",
      "{'batchcomplete': '', 'query': {'pages': {'-1': {'ns': 0, 'title': 'Tomás Pimentel', 'missing': '', 'contentmodel': 'wikitext', 'pagelanguage': 'en', 'pagelanguagehtmlcode': 'en', 'pagelanguagedir': 'ltr', 'fullurl': 'https://en.wikipedia.org/wiki/Tom%C3%A1s_Pimentel', 'editurl': 'https://en.wikipedia.org/w/index.php?title=Tom%C3%A1s_Pimentel&action=edit', 'canonicalurl': 'https://en.wikipedia.org/wiki/Tom%C3%A1s_Pimentel'}}}}\n",
      "{'batchcomplete': '', 'query': {'pages': {'-1': {'ns': 0, 'title': 'Richard Sumah', 'missing': '', 'contentmodel': 'wikitext', 'pagelanguage': 'en', 'pagelanguagehtmlcode': 'en', 'pagelanguagedir': 'ltr', 'fullurl': 'https://en.wikipedia.org/wiki/Richard_Sumah', 'editurl': 'https://en.wikipedia.org/w/index.php?title=Richard_Sumah&action=edit', 'canonicalurl': 'https://en.wikipedia.org/wiki/Richard_Sumah'}}}}\n",
      "{'batchcomplete': '', 'query': {'pages': {'-1': {'ns': 0, 'title': \"Segun ''Aeroland'' Adewale\", 'missing': '', 'contentmodel': 'wikitext', 'pagelanguage': 'en', 'pagelanguagehtmlcode': 'en', 'pagelanguagedir': 'ltr', 'fullurl': 'https://en.wikipedia.org/wiki/Segun_%27%27Aeroland%27%27_Adewale', 'editurl': 'https://en.wikipedia.org/w/index.php?title=Segun_%27%27Aeroland%27%27_Adewale&action=edit', 'canonicalurl': 'https://en.wikipedia.org/wiki/Segun_%27%27Aeroland%27%27_Adewale'}}}}\n",
      "{'batchcomplete': '', 'query': {'pages': {'-1': {'ns': 0, 'title': 'Bashir Bililiqo', 'missing': '', 'contentmodel': 'wikitext', 'pagelanguage': 'en', 'pagelanguagehtmlcode': 'en', 'pagelanguagedir': 'ltr', 'fullurl': 'https://en.wikipedia.org/wiki/Bashir_Bililiqo', 'editurl': 'https://en.wikipedia.org/w/index.php?title=Bashir_Bililiqo&action=edit', 'canonicalurl': 'https://en.wikipedia.org/wiki/Bashir_Bililiqo'}}}}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Use the `request_pageinfo_per_article()` function above to get the article information for each politician.\n",
    "Extract from the response to the Wikipedia API `lastrevid` and keep track of the politicians which did not return a `lastrevid`.\n",
    "\"\"\"\n",
    "politicians_list = [] # List for politicians with articles that returned lastrevid\n",
    "bad_politician_list = [] # List for politicians with articles that DID NOT return lastrevid\n",
    "\n",
    "# For each row in the politicians dataframe, obtain article information about the politician\n",
    "# via `request_pageinfo_per_article()` function, then extract and save `name` as `article_title` and `lastrevid` as `revision_id`.\n",
    "# Keep all other information from row of dataframe as well (country and url).\n",
    "for index, row in politicians_df.iterrows():\n",
    "    rd = row.to_dict() # Convert row pandas object to dictionary\n",
    "    article_title = rd['name']\n",
    "    info = request_pageinfo_per_article(article_title)\n",
    "    info_num = list(info['query']['pages'].keys())[0] # Trick to get key for nested dictionary needed to obtain lastrevid from returned json schema\n",
    "    # Not all politicians return a `lastrevid`, so use try/except block and save politicians in seperate list that do not return `lastrevid`\n",
    "    try:\n",
    "        rev_id = info['query']['pages'][info_num]['lastrevid']\n",
    "        rd['revision_id'] = rev_id\n",
    "        politicians_list.append(rd)\n",
    "    except:\n",
    "        print(info) # Print out each politician info that did not have `lastrevid`\n",
    "        bad_politician_list.append(rd)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "45130980-b680-4dd8-8f45-319a0cb70451",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Pickle lists in case something goes wrong.\n",
    "These lists can be loaded later so that API calls to Wikipedia for `revision_id` do not need to be made again.\n",
    "\"\"\"\n",
    "# Pickle the lists\n",
    "with open('bad_good_politicians_HW2lists.pkl', 'wb') as f:\n",
    "    pickle.dump((politicians_list,bad_politician_list), f)  # Pickle both lists as a tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cab18f23-a5f9-4f99-b239-4b24adcd13ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Constants setup to make calls to the Wikipedia ORES algorithm for classification of article quality.\n",
    "\"\"\"\n",
    "# The current LiftWing ORES API endpoint and prediction model\n",
    "API_ORES_LIFTWING_ENDPOINT = \"https://api.wikimedia.org/service/lw/inference/v1/models/{model_name}:predict\"\n",
    "API_ORES_EN_QUALITY_MODEL = \"enwiki-articlequality\"\n",
    "\n",
    "# The throttling rate is a function of the Access token that you are granted when you request the token. The constants\n",
    "# come from dissecting the token and getting the rate limits from the granted token. An example of that is below.\n",
    "API_LATENCY_ASSUMED = 0.002       # Assuming roughly 2ms latency on the API and network\n",
    "API_THROTTLE_WAIT = ((60.0*60.0)/5000.0)-API_LATENCY_ASSUMED  # The key authorizes 5000 requests per hour\n",
    "\n",
    "# When making automated requests we should include something that is unique to the person making the request\n",
    "# This should include an email - your UW email would be good to put in there\n",
    "   \n",
    "# Because all LiftWing API requests require some form of authentication, you need to provide your access token\n",
    "# as part of the header too\n",
    "REQUEST_HEADER_TEMPLATE = {\n",
    "    'User-Agent': \"dtropf@uw.edu, University of Washington, MSDS DATA 512 - AUTUMN 2024\",\n",
    "    'Content-Type': 'application/json',\n",
    "    'Authorization': \"Bearer {access_token}\"\n",
    "}\n",
    "\n",
    "# This is a template for the parameters that we need to supply in the headers of an API request\n",
    "REQUEST_HEADER_PARAMS_TEMPLATE = {\n",
    "    'email_address' : \"\",         # your email address should go here\n",
    "    'access_token'  : \"\"          # the access token you create will need to go here\n",
    "}\n",
    "\n",
    "\n",
    "# A dictionary of English Wikipedia article titles (keys) and sample revision IDs that can be used for this ORES scoring example\n",
    "ARTICLE_REVISIONS = { 'Bison':1085687913 , 'Northern flicker':1086582504 , 'Red squirrel':1083787665 , 'Chinook salmon':1085406228 , 'Horseshoe bat':1060601936 }\n",
    "\n",
    "# This is a template of the data required as a payload when making a scoring request of the ORES model\n",
    "ORES_REQUEST_DATA_TEMPLATE = {\n",
    "    \"lang\":        \"en\",     # required that its english - we're scoring English Wikipedia revisions\n",
    "    \"rev_id\":      \"\",       # this request requires a revision id\n",
    "    \"features\":    True\n",
    "}\n",
    "\n",
    "# Obtain USERNAME and ACCESS_TOKEN via environment variables set by using the command `source cred.sh` before running this notebook.\n",
    "# See README.txt for instructions.\n",
    "USERNAME = os.environ['USER_NAME']\n",
    "ACCESS_TOKEN = os.environ['ACCESS_TOKEN']\n",
    "EMAIL_ADDRESS = 'dtropf@uw.edu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f840f5bf-2b3f-48f4-bdaf-2184e045acac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Calls to ORES model for classification of article quality.\n",
    "\"\"\"\n",
    "\n",
    "def request_ores_score_per_article(article_revid = None, email_address=None, access_token=None,\n",
    "                                   endpoint_url = API_ORES_LIFTWING_ENDPOINT, \n",
    "                                   model_name = API_ORES_EN_QUALITY_MODEL, \n",
    "                                   request_data = ORES_REQUEST_DATA_TEMPLATE, \n",
    "                                   header_format = REQUEST_HEADER_TEMPLATE, \n",
    "                                   header_params = REQUEST_HEADER_PARAMS_TEMPLATE):\n",
    "    \"\"\"\n",
    "    Call Wikipedia ORES API to obtain a classification of an article based on `article_revid`.\n",
    "    Returns JSON object which prediction (quality) of article will be obtained.\n",
    "    \"\"\"\n",
    "    \n",
    "    #    Make sure we have an article revision id, email and token\n",
    "    #    This approach prioritizes the parameters passed in when making the call\n",
    "    if article_revid:\n",
    "        request_data['rev_id'] = article_revid\n",
    "    if email_address:\n",
    "        header_params['email_address'] = email_address\n",
    "    if access_token:\n",
    "        header_params['access_token'] = access_token\n",
    "    \n",
    "    #   Making a request requires a revision id - an email address - and the access token\n",
    "    if not request_data['rev_id']:\n",
    "        raise Exception(\"Must provide an article revision id (rev_id) to score articles\")\n",
    "    if not header_params['email_address']:\n",
    "        raise Exception(\"Must provide an 'email_address' value\")\n",
    "    if not header_params['access_token']:\n",
    "        raise Exception(\"Must provide an 'access_token' value\")\n",
    "    \n",
    "    # Create the request URL with the specified model parameter - default is a article quality score request\n",
    "    request_url = endpoint_url.format(model_name=model_name)\n",
    "    \n",
    "    # Create a compliant request header from the template and the supplied parameters\n",
    "    headers = dict()\n",
    "    for key in header_format.keys():\n",
    "        headers[str(key)] = header_format[key].format(**header_params)\n",
    "    \n",
    "    # make the request\n",
    "    try:\n",
    "        # we'll wait first, to make sure we don't exceed the limit in the situation where an exception\n",
    "        # occurs during the request processing - throttling is always a good practice with a free data\n",
    "        # source like ORES - or other community sources\n",
    "        if API_THROTTLE_WAIT > 0.0:\n",
    "            time.sleep(API_THROTTLE_WAIT)\n",
    "        #response = requests.get(request_url, headers=headers)\n",
    "        response = requests.post(request_url, headers=headers, data=json.dumps(request_data))\n",
    "        json_response = response.json()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        json_response = None\n",
    "    return json_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad2ef11-2931-49ad-9564-18688e9f4274",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Obtain an `article_quality` ORES value for the Wikipedia article associated with each politician.\n",
    "Also keep track of the articles which did not return a prediction.\n",
    "\"\"\"\n",
    "final_politician_list = [] # List for politicians with articles that returned ORES classification\n",
    "bad_final_politician_list = [] # List for politicians with articles that DID NOT return an ORES classification\n",
    "\n",
    "# For each politician, use their `revision_id` to call the `request_ores_score_per_article()` function\n",
    "# and obtain the predicted classification for the article.\n",
    "for i, p in enumerate(politicians_list):\n",
    "    revision_id = p['revision_id']\n",
    "\n",
    "    # A politician may not return an ORES prediction, so use try/except block\n",
    "    try:\n",
    "        # ORES prediction\n",
    "        score = request_ores_score_per_article(article_revid=revision_id,\n",
    "                                           email_address=EMAIL_ADDRESS,\n",
    "                                           access_token=ACCESS_TOKEN)\n",
    "\n",
    "        aq_id = list(score['enwiki']['scores'].keys())[0] # Trick to get to prediction score in nested dictionary of resonse to API\n",
    "        article_quality = score['enwiki']['scores'][aq_id]['articlequality']['score']['prediction']\n",
    "        p['article_quality'] = article_quality\n",
    "        print(i, p)\n",
    "    except:\n",
    "        bad_final_politician_list.append(p)\n",
    "        print(f'BAD: {i} {p}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a864930c-66fd-4159-8296-58e68d552d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Pickle lists in case something goes wrong\n",
    "\"\"\"\n",
    "\n",
    "# Pickle the lists\n",
    "with open('article_quality_politicians_HW2lists.pkl', 'wb') as f:\n",
    "    pickle.dump((politicians_list), f)  # Pickle both lists as a tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "858290a1-d215-48e3-88f5-429385cbebb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'region': 'WORLD', 'population': 8009.0, 'country_list': [], 'population_list': []}\n",
      "{'region': 'AFRICA', 'population': 1453.0, 'country_list': [], 'population_list': []}\n",
      "{'region': 'NORTHERN AFRICA', 'population': 256.0, 'country_list': ['Algeria', 'Egypt', 'Libya', 'Morocco', 'Sudan', 'Tunisia', 'Western Sahara'], 'population_list': [46.8, 105.2, 6.9, 37.0, 48.1, 11.9, 0.6]}\n",
      "{'region': 'WESTERN AFRICA', 'population': 442.0, 'country_list': ['Benin', 'Burkina Faso', 'Cape Verde', \"Cote d'Ivoire\", 'Gambia', 'Ghana', 'Guinea', 'GuineaBissau', 'Liberia', 'Mali', 'Mauritania', 'Niger', 'Nigeria', 'Senegal', 'Sierra Leone', 'Togo'], 'population_list': [13.7, 22.9, 0.6, 30.9, 2.8, 34.1, 14.2, 2.2, 5.4, 23.3, 4.9, 27.2, 223.8, 18.3, 8.9, 9.1]}\n",
      "{'region': 'EASTERN AFRICA', 'population': 483.0, 'country_list': ['Burundi', 'Comoros', 'Djibouti', 'Eritrea', 'Ethiopia', 'Kenya', 'Madagascar', 'Malawi', 'Mauritius', 'Mayotte', 'Mozambique', 'Reunion', 'Rwanda', 'Seychelles', 'Somalia', 'South Sudan', 'Tanzania', 'Uganda', 'Zambia', 'Zimbabwe'], 'population_list': [13.2, 0.9, 1.1, 3.7, 126.5, 55.1, 30.4, 19.8, 1.3, 0.3, 33.9, 0.9, 14.1, 0.1, 18.1, 11.1, 67.4, 48.6, 20.2, 16.7]}\n",
      "{'region': 'MIDDLE AFRICA', 'population': 202.0, 'country_list': ['Angola', 'Cameroon', 'Central African Republic', 'Chad', 'Congo', 'Congo DR', 'Equatorial Guinea', 'Gabon', 'Sao Tome and Principe'], 'population_list': [36.7, 28.1, 6.2, 18.3, 6.1, 102.3, 1.7, 2.4, 0.2]}\n",
      "{'region': 'SOUTHERN AFRICA', 'population': 70.0, 'country_list': ['Botswana', 'eSwatini', 'Lesotho', 'Namibia', 'South Africa'], 'population_list': [2.7, 1.2, 2.3, 2.6, 60.7]}\n",
      "{'region': 'NORTHERN AMERICA', 'population': 375.0, 'country_list': ['Canada', 'United States'], 'population_list': [40.1, 335.0]}\n",
      "{'region': 'LATIN AMERICA AND THE CARIBBEAN', 'population': 652.0, 'country_list': [], 'population_list': []}\n",
      "{'region': 'CENTRAL AMERICA', 'population': 182.0, 'country_list': ['Belize', 'Costa Rica', 'El Salvador', 'Guatemala', 'Honduras', 'Mexico', 'Nicaragua', 'Panama'], 'population_list': [0.5, 5.3, 6.4, 18.1, 9.7, 131.0, 6.8, 4.5]}\n",
      "{'region': 'CARIBBEAN', 'population': 44.0, 'country_list': ['Antigua and Barbuda', 'Bahamas', 'Barbados', 'Cuba', 'Curacao', 'Dominica', 'Dominican Republic', 'Grenada', 'Guadeloupe', 'Haiti', 'Jamaica', 'Martinique', 'Puerto Rico', 'St. Kitts and Nevis', 'St. Lucia', 'St. Vincent and the Grenadines', 'Trinidad and Tobago'], 'population_list': [0.1, 0.4, 0.3, 11.0, 0.1, 0.1, 11.3, 0.1, 0.4, 11.6, 2.8, 0.3, 3.3, 0.1, 0.2, 0.1, 1.4]}\n",
      "{'region': 'SOUTH AMERICA', 'population': 426.0, 'country_list': ['Argentina', 'Bolivia', 'Brazil', 'Chile', 'Colombia', 'Ecuador', 'French Guiana', 'Guyana', 'Paraguay', 'Peru', 'Suriname', 'Uruguay', 'Venezuela'], 'population_list': [46.3, 12.2, 204.0, 20.0, 52.2, 17.1, 0.3, 0.8, 6.2, 33.8, 0.6, 3.6, 28.8]}\n",
      "{'region': 'ASIA', 'population': 4739.0, 'country_list': [], 'population_list': []}\n",
      "{'region': 'WESTERN ASIA', 'population': 299.0, 'country_list': ['Armenia', 'Azerbaijan', 'Bahrain', 'Cyprus', 'Georgia', 'Iraq', 'Israel', 'Jordan', 'Kuwait', 'Lebanon', 'Oman', 'Palestinian Territory', 'Qatar', 'Saudi Arabia', 'Syria', 'Turkey', 'United Arab Emirates', 'Yemen'], 'population_list': [3.0, 10.2, 1.6, 1.3, 3.8, 45.5, 9.8, 11.4, 4.4, 5.4, 5.0, 5.5, 2.7, 36.9, 23.2, 85.6, 9.5, 34.4]}\n",
      "{'region': 'CENTRAL ASIA', 'population': 80.0, 'country_list': ['Kazakhstan', 'Kyrgyzstan', 'Tajikistan', 'Turkmenistan', 'Uzbekistan'], 'population_list': [19.9, 6.8, 10.2, 7.1, 36.4]}\n",
      "{'region': 'SOUTH ASIA', 'population': 2029.0, 'country_list': ['Afghanistan', 'Bangladesh', 'Bhutan', 'India', 'Iran', 'Maldives', 'Nepal', 'Pakistan', 'Sri Lanka'], 'population_list': [42.4, 173.5, 0.8, 1428.6, 89.2, 0.6, 30.9, 240.5, 22.7]}\n",
      "{'region': 'SOUTHEAST ASIA', 'population': 682.0, 'country_list': ['Brunei', 'Cambodia', 'Indonesia', 'Laos', 'Malaysia', 'Myanmar', 'Philippines', 'Singapore', 'Thailand', 'Timor Leste', 'Vietnam'], 'population_list': [0.4, 17.0, 278.7, 7.5, 33.4, 55.4, 117.3, 5.8, 66.0, 1.4, 98.9]}\n",
      "{'region': 'EAST ASIA', 'population': 1648.0, 'country_list': ['China', 'China (Hong Kong SAR)', 'China (Macao SAR)', 'Japan', 'Korea (North)', 'Korea (South)', 'Mongolia', 'Taiwan'], 'population_list': [1411.3, 7.3, 0.7, 124.5, 26.2, 51.4, 3.5, 23.4]}\n",
      "{'region': 'EUROPE', 'population': 744.0, 'country_list': [], 'population_list': []}\n",
      "{'region': 'NORTHERN EUROPE', 'population': 108.0, 'country_list': ['Denmark', 'Estonia', 'Finland', 'Iceland', 'Ireland', 'Latvia', 'Lithuania', 'Norway', 'Sweden', 'United Kingdom'], 'population_list': [5.9, 1.4, 5.6, 0.4, 5.2, 1.9, 2.9, 5.5, 10.5, 68.1]}\n",
      "{'region': 'WESTERN EUROPE', 'population': 199.0, 'country_list': ['Austria', 'Belgium', 'France', 'Germany', 'Liechtenstein', 'Luxembourg', 'Monaco', 'Netherlands', 'Switzerland'], 'population_list': [9.2, 11.8, 65.9, 84.9, 0.0, 0.7, 0.0, 17.9, 8.8]}\n",
      "{'region': 'EASTERN EUROPE', 'population': 285.0, 'country_list': ['Belarus', 'Bulgaria', 'Czechia', 'Hungary', 'Moldova', 'Poland', 'Romania', 'Russia', 'Slovakia', 'Ukraine'], 'population_list': [9.2, 6.4, 10.9, 9.6, 3.4, 37.7, 19.1, 146.9, 5.4, 36.7]}\n",
      "{'region': 'SOUTHERN EUROPE', 'population': 152.0, 'country_list': ['Albania', 'Andorra', 'Bosnia Herzegovina', 'Croatia', 'Greece', 'Italy', 'Kosovo', 'Malta', 'Montenegro', 'North Macedonia', 'Portugal', 'San Marino', 'Serbia', 'Slovenia', 'Spain'], 'population_list': [2.7, 0.1, 3.4, 3.8, 10.6, 58.8, 1.7, 0.6, 0.6, 1.8, 10.5, 0.0, 6.6, 2.1, 48.3]}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This cell for grouping countries with their respective regions.\n",
    "The `population_by_country_AUG.2024.csv` file has a heiarchy of region with countries inside said region in the same column.\n",
    "Thus, some data processing needs to be done in order to properly associate a politician with a specific region.\n",
    "\n",
    "The goal is to obtain a list of dictionaries, each dictionary is associated with a single region and will have all countries\n",
    "of the region as well as the respective populations of each country.\n",
    "\n",
    "Using the list of dictionaries, the country a politician is from can be found in one of these dictionaries and thus a region can then\n",
    "be assigned to the politician.\n",
    "\n",
    "NOTE: This cell assumes that the data is structured such that the 'Geography' value (column) in the first row is a \"region\"\n",
    "      signified by a string that is in all caps.\n",
    "\"\"\"\n",
    "\n",
    "region_list = [] # List of dictionaries, one dictionary for each region\n",
    "# Cycle through each row of the population csv file, determine if the value in `Geography`\n",
    "# column is all caps (indicates it is a region), then aggregate all non-capitalized values beneath\n",
    "# the region into a list and save in the region dictionary.\n",
    "for index, row in population_df.iterrows():\n",
    "    region = row.values[0]\n",
    "    population = row.values[1]\n",
    "    if region.isupper(): # Test if region\n",
    "        if index > 0: # First value in data is a region, so does not have a list of countries and associated populations\n",
    "            region_dict['country_list'] = country_list # Save all countries in region\n",
    "            region_dict['population_list'] = population_list # Save population of each country in the region\n",
    "            region_list.append(region_dict)\n",
    "            print(region_dict)\n",
    "        region_dict = {'region': region, 'population': population} # Create new dictionary for next region\n",
    "        country_list = [] # Empty list for new region countries\n",
    "        population_list = [] # Empty list for new region country populations\n",
    "    else: # Logic if country and NOT region\n",
    "        country_list.append(region)\n",
    "        population_list.append(population)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5f358c21-5358-45bc-a9b1-077b84a1e277",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This cell bundles together `country`, `region`, `population`, `article_title`, `revision_id`, and `article_quality`\n",
    "from the various objects collected from cells above into a single dictionary.\n",
    "\n",
    "The dictionary is this transformed into a Pandas DataFrame and finally saved out as a CSV.\n",
    "\n",
    "NOTE: The value `population` refers to the `country` population and not the `region` population.\n",
    "\"\"\"\n",
    "\n",
    "# Schema for final output to csv\n",
    "final_dict = {'country': [], 'region': [], 'population': [], 'article_title': [], \n",
    "              'revision_id': [], 'article_quality': []}\n",
    "\n",
    "# For each politician, get the country, article, revision_id, article_quality, country population\n",
    "for i, p in enumerate(politicians_list):\n",
    "    if p in bad_final_politician_list: # If politician did not have an ORES score or otherwise, skip that politician\n",
    "        continue\n",
    "    country = p['country']\n",
    "    article_title = p['name']\n",
    "    revision_id = p['revision_id']\n",
    "    article_quality = p['article_quality']\n",
    "\n",
    "    # Loop through each region to find out which region the politician belongs to based on their country\n",
    "    for r in region_list:\n",
    "        if country in r['country_list']:\n",
    "            region = r['region']\n",
    "            population = r['population_list'][r['country_list'].index(country)]\n",
    "\n",
    "    # Save all results to dictionary\n",
    "    final_dict['country'].append(country)\n",
    "    final_dict['region'].append(region)\n",
    "    final_dict['population'].append(population)\n",
    "    final_dict['article_title'].append(article_title)\n",
    "    final_dict['revision_id'].append(revision_id)\n",
    "    final_dict['article_quality'].append(article_quality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5513c48a-a4ab-4bd6-b693-2c92222f4acb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>region</th>\n",
       "      <th>population</th>\n",
       "      <th>article_title</th>\n",
       "      <th>revision_id</th>\n",
       "      <th>article_quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>SOUTH ASIA</td>\n",
       "      <td>42.4</td>\n",
       "      <td>Majah Ha Adrif</td>\n",
       "      <td>1233202991</td>\n",
       "      <td>Start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>SOUTH ASIA</td>\n",
       "      <td>42.4</td>\n",
       "      <td>Haroon al-Afghani</td>\n",
       "      <td>1230459615</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>SOUTH ASIA</td>\n",
       "      <td>42.4</td>\n",
       "      <td>Tayyab Agha</td>\n",
       "      <td>1225661708</td>\n",
       "      <td>Start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>SOUTH ASIA</td>\n",
       "      <td>42.4</td>\n",
       "      <td>Khadija Zahra Ahmadi</td>\n",
       "      <td>1234741562</td>\n",
       "      <td>Stub</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>SOUTH ASIA</td>\n",
       "      <td>42.4</td>\n",
       "      <td>Aziza Ahmadyar</td>\n",
       "      <td>1195651393</td>\n",
       "      <td>Start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7141</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>EASTERN AFRICA</td>\n",
       "      <td>16.7</td>\n",
       "      <td>Josiah Tongogara</td>\n",
       "      <td>1203429435</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7142</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>EASTERN AFRICA</td>\n",
       "      <td>16.7</td>\n",
       "      <td>Langton Towungana</td>\n",
       "      <td>1246280093</td>\n",
       "      <td>Stub</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7143</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>EASTERN AFRICA</td>\n",
       "      <td>16.7</td>\n",
       "      <td>Sengezo Tshabangu</td>\n",
       "      <td>1228478288</td>\n",
       "      <td>Start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7144</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>EASTERN AFRICA</td>\n",
       "      <td>16.7</td>\n",
       "      <td>Herbert Ushewokunze</td>\n",
       "      <td>959111842</td>\n",
       "      <td>Stub</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7145</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>EASTERN AFRICA</td>\n",
       "      <td>16.7</td>\n",
       "      <td>Denis Walker</td>\n",
       "      <td>1247902630</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7146 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          country          region  population         article_title  \\\n",
       "0     Afghanistan      SOUTH ASIA        42.4        Majah Ha Adrif   \n",
       "1     Afghanistan      SOUTH ASIA        42.4     Haroon al-Afghani   \n",
       "2     Afghanistan      SOUTH ASIA        42.4           Tayyab Agha   \n",
       "3     Afghanistan      SOUTH ASIA        42.4  Khadija Zahra Ahmadi   \n",
       "4     Afghanistan      SOUTH ASIA        42.4        Aziza Ahmadyar   \n",
       "...           ...             ...         ...                   ...   \n",
       "7141     Zimbabwe  EASTERN AFRICA        16.7      Josiah Tongogara   \n",
       "7142     Zimbabwe  EASTERN AFRICA        16.7     Langton Towungana   \n",
       "7143     Zimbabwe  EASTERN AFRICA        16.7     Sengezo Tshabangu   \n",
       "7144     Zimbabwe  EASTERN AFRICA        16.7   Herbert Ushewokunze   \n",
       "7145     Zimbabwe  EASTERN AFRICA        16.7          Denis Walker   \n",
       "\n",
       "      revision_id article_quality  \n",
       "0      1233202991           Start  \n",
       "1      1230459615               B  \n",
       "2      1225661708           Start  \n",
       "3      1234741562            Stub  \n",
       "4      1195651393           Start  \n",
       "...           ...             ...  \n",
       "7141   1203429435               C  \n",
       "7142   1246280093            Stub  \n",
       "7143   1228478288           Start  \n",
       "7144    959111842            Stub  \n",
       "7145   1247902630               C  \n",
       "\n",
       "[7146 rows x 6 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "This final cell converts the `final_dict` object in the cell above to a Pandas DataFrame then saves that data to a csv file.\n",
    "\"\"\"\n",
    "final_df = pd.DataFrame(final_dict)\n",
    "final_df.to_csv('wp_politicians_by_country.csv', index=False)\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06182905-22d9-4f34-9d82-a8930df67dcd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
